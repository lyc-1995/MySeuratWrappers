#' @include internal.R
#'
NULL

#' @param latent.data effects to regress out (data.frame)
#' @param n.features number of features to use when estimating theta (default uses all features)
#' @param min.cells only use features that have been observed in at least this many cells
#' @param regress.features feature to run regression for (default uses all features)
#' @param res.clip.range numeric of length two specifying the min and max values the results will be clipped to
#' @param min.theta minimum theta to use in NB regression
#' @param residual.type string specifying the type of residual used (default is pearson)
#' @param bin.size number of features to put in each bin (to show progress)
#' @param theta.given skip the first step and use the fitted thetas from a previous run
#'
#' @import future
#' @import future.apply
#' @import Matrix
#' @importFrom MASS theta.ml negative.binomial
#' @importFrom stats glm loess residuals approx
#' @importFrom utils txtProgressBar setTxtProgressBar
#'
#' @rdname RegressOutNBreg
#' @export
#'
RegressOutNBreg.default <- function(
  object,
  latent.data,
  n.features = NULL,
  min.cells = 3,
  regress.features = NULL,
  res.clip.range = c(-30, 30),
  min.theta = 0.01,
  residual.type = 'pearson',
  bin.size = 128,
  theta.given = NULL
) {
  my.lapply <- ifelse(
    test = nbrOfWorkers() == 1,
    yes = pblapply,
    no = future_lapply
  )
  # in the first step we use all features, except if n_features.step1 has been set
  observed.features <- Matrix::rowSums(x = object > 0)
  regress.features <- regress.features %||% rownames(x = object)
  regress.features <- intersect(x = regress.features, y = rownames(x = object)[observed.features >= min.cells])
  features.step1 <- rownames(x = object)[observed.features >= min.cells]
  if (!is.null(n.features)) {
    # density-sample features to speed up the first step
    raw.mean <- log10(Matrix::rowMeans(x = object[features.step1, ]))
    raw.det.rate <- Matrix::rowMeans(x = object[features.step1, ] > 0)
    dens <- apply(
      X = cbind(raw.mean, raw.det.rate),
      MARGIN = 2,
      FUN = function(y) {
        y.dens <- density(x = y, bw = 'nrd', adjust = 1)
        ret <- approx(x = y.dens$x, y = y.dens$y, xout = y)$y
        return(ret / sum(ret))
      }
    )
    sampling.prob <- 1 / apply(X = dens, MARGIN = 1, FUN = min)
    features.step1 <- sample(x = features.step1, size = n.features, prob = sampling.prob)
  }
  bin.ind <- ceiling(x = 1:length(x = features.step1) / bin.size)
  max.bin <- max(bin.ind)
  message(paste('Regressing out', paste(colnames(latent.data), collapse = ' ')))
  if (!is.null(theta.given)) {
    message('Using previously fitted theta values for NB regression')
    theta.fit <- theta.given
  } else {
    message('First step: Poisson regression (to get initial mean), and estimate theta per feature')
    message('Using ', length(x = features.step1), ' features')
    pb <- txtProgressBar(min = 0, max = max.bin, style = 3)
    theta.estimate <- c()
    for (i in 1:max.bin) {
      features.bin.regress <- features.step1[bin.ind == i]
      bin.theta.estimate <- unlist(
        my.lapply(
          X = features.bin.regress,
          FUN = function(j) {
            as.numeric(
              x = MASS::theta.ml(
                as.numeric(x = unlist(x = object[j, ])),
                glm(as.numeric(x = unlist(x = object[j, ])) ~ ., data = latent.data, family = poisson)$fitted
              )
            )
          }
        ),
        use.names = FALSE
      )
      theta.estimate <- c(theta.estimate, bin.theta.estimate)
      setTxtProgressBar(pb, i)
    }
    close(pb)
    names(theta.estimate) <- features.step1
    umi.mean <- Matrix::rowMeans(x = object[features.step1, ])
    var.estimate <- umi.mean + (umi.mean ^ 2) / theta.estimate
    fit <- loess(log10(var.estimate) ~ log10(umi.mean), span = 0.33)
    regress.features.mean <- rowMeans(x = object[regress.features, ])
    log10.var.fit <- predict(fit, log10(regress.features.mean))
    theta.fit <- (regress.features.mean ^ 2) / (10 ^ log10.var.fit - regress.features.mean)
    to.fix <- theta.fit <= min.theta | is.infinite(x = theta.fit)
    if (any(to.fix)) {
      message(
        'Fitted theta below ',
        min.theta,
        ' for ',
        sum(to.fix),
        ' features, setting them to ',
        min.theta
      )
      theta.fit[to.fix] <- min.theta
    }
    # save theta estimate and fitted theta in object
    misc <- list()
    misc[['NBreg.theta.estimate']] <- theta.estimate
    misc[['NBreg.theta.fit']] <- theta.fit
  }
  message('Second step: NB regression with fixed theta for ', length(x = regress.features), ' features')
  bin.ind <- ceiling(x = 1:length(x = regress.features) / bin.size)
  max.bin <- max(bin.ind)
  pb <- txtProgressBar(min = 0, max = max.bin, style = 3, file = stderr())
  res <- c()
  for (i in 1:max.bin) {
    features.bin.regress <- regress.features[bin.ind == i]
    names(features.bin.regress) <- features.bin.regress
    bin.res.lst <- my.lapply(
      X = features.bin.regress,
      FUN = function(j) {
        fit <- 0
        try(
          fit <- glm(
            as.numeric(x = unlist(x = object[j, ])) ~ .,
            data = latent.data,
            family = MASS::negative.binomial(theta = theta.fit[j])
          ),
          silent = TRUE
        )
        if (class(fit)[1] == 'numeric') {
          message <-
            sprintf(
              'glm and family=negative.binomial(theta=%f) failed for feature %s; falling back to scale(log10(y+1))',
              theta.fit[j],
              j
            )
          res <- scale(x = log10(as.numeric(x = unlist(x = object[j, ])) + 1))[, 1]
        } else {
          message <- NULL
          res <- residuals(object = fit, type = residual.type)
        }
        return(list(res = res, message = message))
      }
    )
    # Print message to keep track of the features for which glm failed to converge
    message <- unlist(x = lapply(X = bin.res.lst, FUN = function(l) { return(l$message) }), use.names = FALSE)
    if (!is.null(x = message)) {
      message(paste(message, collapse = '\n'))
    }
    bin.res.lst <- lapply(X = bin.res.lst, FUN = function(l) { return(l$res) })
    res <- rbind(res, do.call(rbind, bin.res.lst))
    setTxtProgressBar(pb, i)
  }
  close(pb)
  dimnames(x = res) <- list(regress.features, colnames(x = object))
  res[res < res.clip.range[1]] <- res.clip.range[1]
  res[res > res.clip.range[2]] <- res.clip.range[2]
  misc[['NBreg.residuals']] <- res
  rm(res);gc(reset = TRUE)
  return(misc)
}

#' @param assay Name of assay to pull the count data from
#' @param new.assay.name Name for the new assay containing the normolized data
#' @param cells Cells used to do regularized NB regression; default is NULL
#' @param latent.var The independent variables to regress out as a character vector; must match column names in meta.data
#' @param slot Slot where Pearson residual will return; default is scale.data
#' @param variable.features.n Use this many features as variable features after ranking by residual z-score; default is 2000
#' @param variable.features.z.th Instead of setting a fixed number of variable features, use this residual variance cutoff; this is only used when \code{variable.features.n} is set to NULL; default is 1
#' @param return.variable.features Whether or not return the variable features; default is FALSE
#'
#' @import Seurat
#' @rdname RegressOutNBreg
#' @export
#' @method RegressOutNBreg Seurat
#'
RegressOutNBreg.Seurat <- function(
  object,
  assay = NULL,
  new.assay.name = NULL,
  cells = NULL,
  latent.var,
  slot = 'scale.data',
  variable.features.n = 2000,
  variable.features.z.th = 1,
  return.variable.features = FALSE,
  ...
) {
  assay <- assay %||% DefaultAssay(object = object)
  cells <- cells %||% colnames(object[[assay]])
  latent.data <- object@meta.data[cells, latent.var, drop = FALSE]
  umi <- GetAssayData(object = object, assay = assay, slot = 'counts')
  misc <- RegressOutNBreg(
    object = umi[, cells],
    latent.data = latent.data,
    ...
  )
  features.z.score <- scale(sqrt(apply(misc[['NBreg.residuals']]^2, 1, sum)))
  names(features.z.score) <- rownames(misc[['NBreg.residuals']])
  features.z.score <- sort(x = features.z.score, decreasing = TRUE)
  if (!is.null(x = variable.features.n)) {
    top.features <- names(x = features.z.score)[1:min(variable.features.n, length(x = features.z.score))]
  } else {
    top.features <- names(x = features.z.score)[features.z.score >= variable.features.z.th]
  }
  misc[['Variable.features']] <- data.frame(features.z.score = features.z.score,
                                            is.variable = names(features.z.score) %in% top.features,
                                            row.names = names(features.z.score))
  new.assay.name <- new.assay.name %||% 'NBreg'
  object[[new.assay.name]] <- CreateAssayObject(counts = umi)
  object[[new.assay.name]] <- NormalizeData(object[[new.assay.name]], normalization.method = 'LogNormalize')
  object[[new.assay.name]] <- SetAssayData(object = object[[new.assay.name]], slot = slot, new.data = misc[['NBreg.residuals']])
  misc[['NBreg.residuals']] <- NULL
  Misc(object = object[[new.assay.name]], slot = 'NBreg.out') <- misc
  if (return.variable.features) {
    VariableFeatures(object[[new.assay.name]]) <- rownames(misc[['Variable.features']])[misc[['Variable.features']]$is.variable]
  }
  rm(misc); gc(reset = TRUE)
  message(paste('Set default assay to', new.assay.name))
  DefaultAssay(object = object) <- new.assay.name
  object <- LogSeuratCommand(object = object)
  return(object)
}
